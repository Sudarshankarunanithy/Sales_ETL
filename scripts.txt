df_sales = spark.read.option("header",True).csv("hdfs://hdfs-namenode:9000/sales_etl/input/sales.csv")
df_products = spark.read.json("hdfs://hdfs-namenode:9000/sales_etl/input/products.json")


spark.sql("""
Create or Replace Temp View Sales_enriched as
SELECT s.sale_id, s.product_id, s.quantity,p.product_name, p.unit_price, s.quantity*p.unit_price as total_price,
Case
when s.quantity*p.unit_price >=1000 then 'High'
when s.quantity*p.unit_price >=500 then 'Medium'
Else 'Low'
End As sale_Value_category
From Sales_raw S
join products_raw p on s.product_id = p.product_id""")


df_output.write.mode("overwrite").option("header", True).csv("hdfs:hdfs-namenode:9000/sales_etl/output/final_csv")

df_output.write \
    .mode("overwrite") \
    .option("header", True) \
    .csv("hdfs://hdfs-namenode:9000/sales_etl/output/final_csv")



df_output.write.mode("overwrite").parquet("hdfs://hdfs-namenode:9000/sales_etl/output/final_parquet")
